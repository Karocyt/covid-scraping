{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "papers.ssrn.com.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlyB9xGHk5EQ",
        "colab_type": "text"
      },
      "source": [
        "#Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNCXCKWyAlti",
        "outputId": "e06c878e-35b4-43b0-d6a0-4253bce471c5",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "#!if [ ! -f ArticleScraper.ipynb ]; then \n",
        "!curl https://raw.githubusercontent.com/Karocyt/covid-scraping/master/ArticleScraper.ipynb > ArticleScraper.ipynb\n",
        "#; else echo \"Already done\"; fi\n",
        "%run ArticleScraper.ipynb"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 19035  100 19035    0     0    98k      0 --:--:-- --:--:-- --:--:--   98k\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.6/dist-packages (4.3)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.6/dist-packages (1.26.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from datetime) (2018.9)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.6/dist-packages (from datetime) (5.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from zope.interface->datetime) (46.0.0)\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Fetched 252 kB in 2s (115 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (80.0.3987.87-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xclRHKvdtNMU",
        "colab_type": "text"
      },
      "source": [
        "#Import private SSRN Credentials from Google Drive\n",
        "###Credential file syntax:  \n",
        "[comment]  \n",
        "private_id=xxxx  \n",
        "private_password=xxx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmlPIk0fg4TP",
        "colab_type": "code",
        "outputId": "a4cf2a5c-f2e6-42af-f304-4d09f5e407a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Google drive authentication\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# File params\n",
        "local_save_dir = \"/root/.ssrn\"\n",
        "\n",
        "# Name of your file on Google Drive\n",
        "filename = \"ssrn_credentials.txt\"\n",
        "save_path = \"{0}/{1}\".format(local_save_dir, filename)\n",
        "\n",
        "# Choose/create a local (colab) directory to store the data.\n",
        "local_download_path = os.path.expanduser(local_save_dir)\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# Replace id with id of your folder in GDrive (last field of url), remove curly braces altogether if in root\n",
        "drive_list = drive.ListFile({'q': \"'1xJJ-uaT89wIzJz009ARQdz_BDcuhPyYb' in parents and trashed=false\"}).GetList()\n",
        "f = [x for x in drive_list if x[\"title\"] == filename][0]\n",
        "\n",
        "print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "fname = os.path.join(local_download_path, f['title'])\n",
        "print('downloading to {}'.format(fname))\n",
        "f_ = drive.CreateFile({'id': f['id']})\n",
        "f_.GetContentFile(fname)\n",
        "\n",
        "with open(save_path) as creds:\n",
        "    for i, line in enumerate(creds):\n",
        "        if i == 1:\n",
        "            private_id = line.replace(\"private_id=\", \"\").replace(\"\\n\", \"\")\n",
        "        if i == 2:\n",
        "            private_password = line.replace(\"private_password=\", \"\").replace(\"\\n\", \"\")\n",
        "\n",
        "# IDs now in private_id and private_password variables"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: ssrn_credentials.txt, id: 1SUrcAKp-_1PjRZx6j9hMXgpVL0b4yZke\n",
            "downloading to /root/.ssrn/ssrn_credentials.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R9aTHdQlNCR",
        "colab_type": "text"
      },
      "source": [
        "#Dummy input for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l_CKHDa_mai_",
        "colab": {}
      },
      "source": [
        "example_dicts = [{'authors': 'C You, Y Deng, W Hu, J Sun, Q Lin, F Zhou… - Available at SSRN …, 2020 - papers.ssrn.com',\n",
        "  'extra_link': 'https://www.medrxiv.org/content/medrxiv/early/2020/02/11/2020.02.08.20021253.full.pdf',\n",
        "  'extra_link_text': '[PDF] medrxiv.org',\n",
        "  'link': 'https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3539694',\n",
        "  'preview': 'Background: The 2019 novel coronavirus (2019-nCoV) outbreak in Wuhan, China has\\nattracted world-wide attention. As of February 11, 2020, a total of 44,730 cases of\\npneumonia associated with the 2019-nCoV were confirmed by the National Health …',\n",
        "  'title': 'Estimation of the Time-Varying Reproduction Number of COVID-19 Outbreak in China'},\n",
        " {'authors': 'J Gao, P Zheng, Y Jia, H Chen, Y Mao… - Available at SSRN …, 2020 - papers.ssrn.com',\n",
        "  'extra_link': '',\n",
        "  'extra_link_text': '',\n",
        "  'link': 'https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3541120',\n",
        "  'preview': 'Background: Huge citizens expos social media during a novel coronavirus disease (COVID-\\n19) outbroke in Wuhan, China. We assess the prevalence of mental health problems and\\nexamine their association with social media exposure. Methods: We conducted a cross …',\n",
        "  'title': 'Mental Health Problems and Social Media Exposure During COVID-19 Outbreak'},\n",
        " {'authors': 'C GU, W Jiang, T Zhao, B Zheng - Available at SSRN 3551006, 2020 - papers.ssrn.com',\n",
        "  'extra_link': '',\n",
        "  'extra_link_text': '',\n",
        "  'link': 'https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3551006',\n",
        "  'preview': 'The statistics show that the mortality of COVID-19 is 20 times higher than seasonal flu and\\nclose to that of Spanish flu, hence it is becoming an absolute priority for every country to take\\nefficient measure to limit the transmission of COVID-19. In this short paper, we propose a …',\n",
        "  'title': 'Mathematical Recommendations to Fight Against COVID-19'},\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMByyoXB82mc",
        "colab_type": "text"
      },
      "source": [
        "#SsrnSingleScraper Class \n",
        "\n",
        "Inherits from [ArticleScraper](https://colab.research.google.com/github/Karocyt/covid-scraping/blob/master/ArticleScraper.ipynb).  \n",
        "Scrape one article from SSRN.\n",
        "###Constructor\n",
        "Takes a page dictionary (as given above) in it's constructor.\n",
        "For now can optionnaly takes booleans (load_selenium, load_lxml, load_bs). Default is False and to consider everything True if nothing was specified.\n",
        "\n",
        "###Parse method\n",
        "Takes an optionnal retry_sec parameter (seconds), default is 60, set to None to don't retry.  \n",
        "Return value: dictionary of relevant fields (see [ArticleScraper](https://colab.research.google.com/github/Karocyt/covid-scraping/blob/master/ArticleScraper.ipynb) for more info)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WXSKPyznsTqo",
        "colab": {}
      },
      "source": [
        "class SsrnSingleScraper(ArticleScraper):\n",
        "\n",
        "  @property\n",
        "  def title(self):\n",
        "    return self.wd.title.split(' by ')[0]\n",
        "\n",
        "  @property\n",
        "  def authors(self):\n",
        "    return self.wd.title.split(' by ')[1].split(\" ::\")[0]\n",
        "\n",
        "  @property\n",
        "  def doi(self):\n",
        "    # SSRN seems to be recent pre-publications (not peer-reviewed yet) so no DOI in most cases?\n",
        "    pattern = 'doi.org/'\n",
        "    citation = self.wd.find_element(By.CLASS_NAME, 'suggested-citation').text\n",
        "    ret = 'SSRN-ID' + self.page_dict['link'].split('=')[1]\n",
        "    for word in citation.split(\" \"):\n",
        "      if (word.startswith(pattern)):\n",
        "        ret = word.split(pattern)[1]\n",
        "\n",
        "    return ret\n",
        "\n",
        "  @property\n",
        "  def abstract(self):\n",
        "    div = self.wd.find_element(By.CLASS_NAME, \"abstract-text\")\n",
        "    text = div.find_element(By.TAG_NAME, \"p\").text\n",
        "    return text # might need to remove sections titles and Funding section\n",
        "\n",
        "  @property\n",
        "  def date(self):\n",
        "    text = self.wd.find_element(By.XPATH, '//*[@id=\"selectable\"]').text\n",
        "    # probably many different time formats, try/except might not be the best option\n",
        "    try:\n",
        "      date = datetime.strptime(text.split(\")\")[-2].split(\"(\")[-1], '%m/%d/%Y')\n",
        "    except:\n",
        "      date = datetime.strptime(text.split(\")\")[-2].split(\"(\")[-1], '%B %d, %Y')\n",
        "    return date.strftime(self.date_format)\n",
        "\n",
        "  @property\n",
        "  def body(self):\n",
        "    #self.wd.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[1]/div/div[2]/a').click()\n",
        "    #time.sleep(0.2)\n",
        "    #content = \"\"\n",
        "    #print(os.listdir())\n",
        "    #for file in os.listdir():\n",
        "    #  if file.endswith(\".pdf\"):\n",
        "    #    with open(file, 'rb') as f:\n",
        "    #      pdf_reader = PyPDF2.PdfFileReader(f)\n",
        "    #      for page in pdf_reader.pages:\n",
        "    #        content += page.extractText()\n",
        "    #    os.remove(file)\n",
        "    #    break\n",
        "    #return content # raw full text (with header, abstract, footers, references and so on)\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def source(self):\n",
        "    return \"SSRN\"\n",
        "\n",
        "  @property\n",
        "  def source_impact_factor(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def search_keyword(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def categories(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def licence(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def citations(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def organization(self):\n",
        "    # Using organization of lead author\n",
        "    authors = self.wd.find_element(By.CLASS_NAME, 'authors-full-width')\n",
        "    return authors.find_element(By.TAG_NAME, 'p').text\n",
        "\n",
        "  @property\n",
        "  def keywords(self):\n",
        "    keywords = self.wd.find_element_by_xpath(\"//*[contains(text(), 'Keywords:')]/..\").text.split(': ')[1]\n",
        "    return \",\".join(keywords.split(';'))\n",
        "\n",
        "  @property\n",
        "  def references(self):\n",
        "    # format in references is not consistent, sometimes missing field,\n",
        "    # other times data in the wrong field, hence dirty try/except...\n",
        "    self.wd.find_element_by_xpath('//*[@id=\"references-widget\"]/button').click()\n",
        "    time.sleep(0.2)\n",
        "    li_list = self.wd.find_elements_by_xpath('//*[@id=\"references-widget\"]/ol/li')\n",
        "    refs = []\n",
        "    for elem in li_list:\n",
        "      ref = {}\n",
        "      try:\n",
        "        ref['title'] = elem.find_element(By.CLASS_NAME, 'reference-title').text\n",
        "      except:\n",
        "        ref['title'] = \"\"\n",
        "      \n",
        "      try:\n",
        "        ref['authors'] = elem.find_element(By.CLASS_NAME, 'author-list').text\n",
        "      except:\n",
        "        ref['authors'] = \"\"\n",
        "      \n",
        "      try:\n",
        "        link = elem.find_element(By.TAG_NAME,  'a')\n",
        "        ref['link'] = link.get_attribute('href')\n",
        "      except:\n",
        "        ref['link'] = \"\"\n",
        "      refs.append(ref)\n",
        "    \n",
        "    return refs\n",
        "\n",
        "  @property\n",
        "  def link(self):\n",
        "    return self.page_dict['link']\n",
        "\n",
        "  @property\n",
        "  def extralinks(self):\n",
        "    # self.wd.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[1]/div/div[2]/a').click()\n",
        "    # time.sleep(0.2)\n",
        "    # for file in os.listdir():\n",
        "    #   if file.endswith(\".pdf\"):\n",
        "    #     os.remove(file)\n",
        "    #     break\n",
        "\n",
        "    # self.wd.execute_script(\"window.open()\")\n",
        "    # self.wd.switch_to.window(self.wd.window_handles[-1])\n",
        "\n",
        "\n",
        "    self.wd.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[1]/div/div[2]/a').click()\n",
        "    time.sleep(0.2)\n",
        "    \n",
        "    link = self.wd.current_url\n",
        "\n",
        "    self.wd.back()\n",
        "\n",
        "    # self.wd.close()\n",
        "    # self.wd.switch_to.window(self.wd.window_handles[0])\n",
        "\n",
        "    return link  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CVIFXMO8e92q",
        "colab": {}
      },
      "source": [
        "class SsrnSingleScraper(ArticleScraper):\n",
        "\n",
        "  @property\n",
        "  def title(self):\n",
        "    return self.wd.title.split(' by ')[0]\n",
        "\n",
        "  @property\n",
        "  def authors(self):\n",
        "    return self.wd.title.split(' by ')[1].split(\" ::\")[0]\n",
        "\n",
        "  @property\n",
        "  def doi(self):\n",
        "    # SSRN seems to be recent pre-publications (not peer-reviewed yet) so no DOI in most cases?\n",
        "    pattern = 'doi.org/'\n",
        "    citation = self.wd.find_element(By.CLASS_NAME, 'suggested-citation').text\n",
        "    ret = 'SSRN-ID' + self.page_dict['link'].split('=')[1]\n",
        "    for word in citation.split(\" \"):\n",
        "      if (word.startswith(pattern)):\n",
        "        ret = word.split(pattern)[1]\n",
        "\n",
        "    return ret\n",
        "\n",
        "  @property\n",
        "  def abstract(self):\n",
        "    div = self.wd.find_element(By.CLASS_NAME, \"abstract-text\")\n",
        "    text = div.find_element(By.TAG_NAME, \"p\").text\n",
        "    return text # might need to remove sections titles and Funding section\n",
        "\n",
        "  @property\n",
        "  def date(self):\n",
        "    text = self.wd.find_element(By.XPATH, '//*[@id=\"selectable\"]').text\n",
        "    # probably many different time formats, try/except might not be the best option\n",
        "    try:\n",
        "      date = datetime.strptime(text.split(\")\")[-2].split(\"(\")[-1], '%m/%d/%Y')\n",
        "    except:\n",
        "      date = datetime.strptime(text.split(\")\")[-2].split(\"(\")[-1], '%B %d, %Y')\n",
        "    return date.strftime(self.date_format)\n",
        "\n",
        "  @property\n",
        "  def body(self):\n",
        "    #self.wd.find_element(By.XPATH, '//*[@id=\"maincontent\"]/div[1]/div[1]/div/div[2]/a').click()\n",
        "    #time.sleep(0.2)\n",
        "    #content = \"\"\n",
        "    #print(os.listdir())\n",
        "    #for file in os.listdir():\n",
        "    #  if file.endswith(\".pdf\"):\n",
        "    #    with open(file, 'rb') as f:\n",
        "    #      pdf_reader = PyPDF2.PdfFileReader(f)\n",
        "    #      for page in pdf_reader.pages:\n",
        "    #        content += page.extractText()\n",
        "    #    os.remove(file)\n",
        "    #    break\n",
        "    #return content # raw full text (with header, abstract, footers, references and so on)\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def source(self):\n",
        "    return \"SSRN\"\n",
        "\n",
        "  @property\n",
        "  def source_impact_factor(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def search_keyword(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def categories(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def licence(self):\n",
        "    \"\"\"\n",
        "      Unable to find Article-specific Licensing stuff\n",
        "    \"\"\"\n",
        "    return 'https://www.ssrn.com/index.cfm/en/dmca-notice-policy/'\n",
        "\n",
        "  @property\n",
        "  def citations(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def organization(self):\n",
        "    # Using organization of lead author\n",
        "    authors = self.wd.find_element(By.CLASS_NAME, 'authors-full-width')\n",
        "    return authors.find_element(By.TAG_NAME, 'p').text\n",
        "\n",
        "  @property\n",
        "  def keywords(self):\n",
        "    keywords = self.wd.find_element_by_xpath(\"//*[contains(text(), 'Keywords:')]/..\").text.split(': ')[1]\n",
        "    return \",\".join(keywords.split(';'))\n",
        "\n",
        "  @property\n",
        "  def references(self):\n",
        "    # format in references is not consistent, sometimes missing field,\n",
        "    # other times data in the wrong field, hence dirty try/except...\n",
        "    self.wd.find_element_by_xpath('//*[@id=\"references-widget\"]/button').click()\n",
        "    time.sleep(0.2)\n",
        "    li_list = self.wd.find_elements_by_xpath('//*[@id=\"references-widget\"]/ol/li')\n",
        "    refs = []\n",
        "    for elem in li_list:\n",
        "      ref = {}\n",
        "      try:\n",
        "        ref['title'] = elem.find_element(By.CLASS_NAME, 'reference-title').text\n",
        "      except:\n",
        "        ref['title'] = \"\"\n",
        "      \n",
        "      try:\n",
        "        ref['authors'] = elem.find_element(By.CLASS_NAME, 'author-list').text\n",
        "      except:\n",
        "        ref['authors'] = \"\"\n",
        "      \n",
        "      try:\n",
        "        link = elem.find_element(By.TAG_NAME,  'a')\n",
        "        ref['link'] = link.get_attribute('href')\n",
        "      except:\n",
        "        ref['link'] = \"\"\n",
        "      refs.append(ref)\n",
        "    \n",
        "    return refs\n",
        "\n",
        "  @property\n",
        "  def link(self):\n",
        "    return self.page_dict['link']\n",
        "\n",
        "  @property\n",
        "  def extralinks(self):\n",
        "    \"\"\"\n",
        "      Unable to get direct download link to the PDF file:\n",
        "      - A click on the download button triggers a download only if logged in,\n",
        "      but is not a direct download link (the url itself brings you back to the\n",
        "      same page)\n",
        "      - When \"plugins.always_open_pdf_externally\" is set to True in Chrome\n",
        "      prefs, the \"show in browser\" triggers a download too but same problem\n",
        "      - In Chrome headless there is no chrome://downloads page to interact with\n",
        "      and get the last download url, no workaround\n",
        "      - Chrome headless does not have any pdf viewer (getting the current_url of\n",
        "      the viewer page should give a good enough link, allowing to download the\n",
        "      file by visiting with \"plugins.always_open_pdf_externally\" set to True)\n",
        "    \"\"\"\n",
        "    return self.page_dict['extra_links']  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h-f5g1Mlbu8",
        "colab_type": "text"
      },
      "source": [
        "#SsrnScraper class and test\n",
        "##SsrnScraper \n",
        "###Constructor\n",
        "Takes id and password as parameters.  \n",
        "Logs in to avoid random redirects to login screen. \n",
        "###Parse method\n",
        "Takes an array of page dictionnaries (see Dummy input section) and an optionnal retry_sec parameter (seconds, default is 60, set to None to don't retry) that will be forwarded to SsrnSingleScraper instances.\n",
        "Return value: yields the next dictionary of relevant fields as return by SsrnSingleScraper class for each page in the given array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dW_w8jyIzwlJ",
        "colab": {}
      },
      "source": [
        "class SsrnScraper():\n",
        "  login_screen = 'https://hq.ssrn.com/login/pubsigninjoin.cfm'\n",
        "\n",
        "  def __init__(self, connect_id, connect_password):\n",
        "    wd = ArticleScraper.wd\n",
        "    wd.get(self.login_screen)\n",
        "    # Needs to login to avoid random \"please connect\" screen\n",
        "    try:\n",
        "      wd.find_element(By.NAME, 'input-email').send_keys(connect_id)\n",
        "      wd.find_element(By.NAME, 'input-pass').send_keys(connect_password)\n",
        "      wd.find_element(By.ID, 'signinBtn').click()\n",
        "      time.sleep(0.5)\n",
        "    except Exception as e:\n",
        "      print(\"WARNING: error while trying to connect via %s\" % (self.login_screen), e)\n",
        "      wd.save_screenshot(\"temp.png\")\n",
        "      display(Image(filename=\"temp.png\"))\n",
        "      # Remember_me might be working\n",
        "      pass\n",
        "\n",
        "  def parse(self, pages_dict, retry_sec = None):\n",
        "    for d in pages_dict:\n",
        "      yield SsrnSingleScraper(d).parse(retry_sec = 2)  \n",
        "\n",
        "scraper = SsrnScraper(private_id, private_password)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StnvI22OlKVx",
        "colab_type": "code",
        "outputId": "1c93e1c8-43b3-4cbc-ed7f-ad176740df4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for d in scraper.parse(example_dicts):\n",
        "  for k in d:\n",
        "    print(k, d[k], sep=\": \")\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "https://hq.ssrn.com/UserHome.cfm?redirectFrom=true\n",
            "Title: Estimation of the Time-Varying Reproduction Number of COVID-19 Outbreak in China\n",
            "Authors: Chong You, Yuhao Deng, Wenjie Hu, Jiarui Sun, Qiushi Lin, Feng Zhou, Cheng Heng Pang, Yuan Zhang, Zhengchao Chen, Xiao-Hua Zhou\n",
            "DOI: SSRN-ID3539694\n",
            "Abstract: Background: The 2019 novel coronavirus (2019-nCoV) outbreak in Wuhan, China has attracted world-wide attention. As of February 11, 2020, a total of 44,730 cases of pneumonia associated with the 2019-nCoV were confirmed by the National Health Commission (NHC) of China.\n",
            "\n",
            "Methods: Three approaches, namely Poisson likelihood-based method (ML), exponential growth rate-based method (EGR) and stochastic Susceptible-Infected-Removed dynamic model-based method (SIR), were implemented to estimate the basic and controlled reproduction numbers.\n",
            "\n",
            "Results: A total of 71 chains of transmission together with dates of symptoms onset and 67 dates of infections were identified among 5,405 confirmed cases outside Hubei as reported by February 2, 2020. Based on this information, we find the serial interval having an average of 4.27 days with a standard deviation of 3.44 days, the incubation period having an average of 5.33 days with a standard deviation of 3.36 days and the infectious period having an average of 10.91 days with a standard deviation of 3.95 days. The estimated controlled reproduction numbers, 𝑅𝑐 , produced by all three methods in all analyzed regions of China are significantly smaller compared with the basic reproduction numbers 𝑅0.\n",
            "\n",
            "Conclusions: The controlled reproduction number is declining. It is lower than one in most regions of China, but still larger than one in Hubei Province. Sustained efforts are needed to further keep/reduce the 𝑅𝑐 to below one in order to end the current epidemic.\n",
            "\n",
            "Funding Statement: The authors stated that they have no financial relationships (regardless of amount of compensation) with any entities.\n",
            "\n",
            "Declaration of Interests: The authors declare there is no conflict of interest.\n",
            "\n",
            "Ethics Approval Statement: The authors stated this was not required.\n",
            "Date: 2020-02-17\n",
            "Full body: None\n",
            "Source: SSRN\n",
            "Source impact factor: None\n",
            "Search keyword: None\n",
            "Category: None\n",
            "Licensing: None\n",
            "Document acquisition date: 2020-03-24\n",
            "Citations: None\n",
            "Organization affiliated: Peking University - Beijing International Center for Mathematical Research\n",
            "Keywords: serial interval, incubation period, infectious period, reproduction rate\n",
            "References: [{'title': '', 'authors': 'C Huang, Y Wang, X Li, L Ren, J Zhao, Y Hu, . . Cheng, Z', 'link': 'https://doi.org/10.1016/s0140-6736(20)30183-5'}, {'title': 'A novel coronavirus outbreak of global health concern', 'authors': 'C Wang, P W Horby, F G Hayden, G F Gao', 'link': 'https://doi.org/10.1016/s0140-6736(20)30185-9'}, {'title': 'Estimation in emerging epidemics: Biases and remedies', 'authors': 'Tom Britton, Gianpaolo Scalia Tomba', 'link': 'https://doi.org/10.1098/rsif.2018.0670'}, {'title': 'Transmission dynamics and control of severe acute respiratory syndrome', 'authors': 'M Lipsitch, T Cohen, B Cooper', 'link': 'https://doi.org/10.1126/science.1086616'}, {'title': '', 'authors': 'R M Anderson, B Anderson, R M May', 'link': ''}, {'title': '', 'authors': 'R Nikbakht, M R Baneshi, A Bahrampour, A Hosseinnataj', 'link': ''}, {'title': '', 'authors': 'Data', 'link': ''}, {'title': 'A likelihood-based method for real-time estimation of the serial interval and reproductive number of an epidemic', 'authors': 'L Forsberg White, M Pagano', 'link': 'https://doi.org/10.1002/sim.3136'}, {'title': 'How generation intervals shape the relationship between growth rates and reproductive numbers', 'authors': 'J Wallinga, M Lipsitch', 'link': 'https://doi.org/10.1098/rspb.2006.3754'}, {'title': '', 'authors': '', 'link': 'https://doi.org/10.1098/rspb.2015.0347'}, {'title': '', 'authors': '', 'link': 'https://doi.org/10.1039/pl9042000131'}, {'title': '', 'authors': '', 'link': ''}, {'title': 'Inference for dynamic and latent variable models via iterated, perturbed Bayes maps', 'authors': 'E L Ionides, D Nguyen, Y Atchad´e, S Stoev, A A King', 'link': 'https://doi.org/10.1073/pnas.1410597112'}, {'title': '', 'authors': 'A A King, E L Ionides, C M Bret´o, S Ellner, B Kendall, H Wearing, M J Ferrari, M Lavine, D C Reuman', 'link': 'https://doi.org/10.18637/jss.v069.i12'}, {'title': '', 'authors': '', 'link': 'https://doi.org/10.4159/harvard.9780674073517.c13'}, {'title': '', 'authors': '', 'link': ''}, {'title': '', 'authors': '', 'link': ''}]\n",
            "Link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3539694\n",
            "Extra links: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3539694\n",
            "\n",
            "\n",
            "https://hq.ssrn.com/UserHome.cfm?redirectFrom=true\n",
            "Title: Mental Health Problems and Social Media Exposure During COVID-19 Outbreak\n",
            "Authors: Junling Gao, Pinping Zheng, Yingnan Jia, Hao Chen, Yimeng Mao, Suhong Chen, Yi Wang, Hua Fu, Junming Dai\n",
            "DOI: SSRN-ID3541120\n",
            "Abstract: Background: Huge citizens expos social media during a novel coronavirus disease (COVID-19) outbroke in Wuhan, China. We assess the prevalence of mental health problems and examine their association with social media exposure.\n",
            "\n",
            "Methods: We conducted a cross-sectional study among Chinese citizens aged ≥18 years old during Jan 31 to Feb 2, 2019. Online survey was used to do rapid assessment. Total of 4872 participants from 31 provinces and autonomous regions were involved in the current study. Besides demographics and social media exposure (SME), depression was assessed by The Chinese version of WHO-Five Well-Being Index (WHO-5) and anxiety was assessed by Chinese version of generalized anxiety disorder scale (GAD-7). multivariable logistic regressions were used to identify associations between social media exposure with mental health problems after controlling for covariates.\n",
            "\n",
            "Findings: The prevalence of depression, anxiety and combination of depression and anxiety (CDA) was 48.3% (95%CI: 46.9%-49.7%), 22.6% (95%CI: 21.4%-23.8%) and 19.4% (95%CI: 18.3%-20.6%) during COVID-19 outbroke in Wuhan, China. More than 80% (95%CI:80.9%-83.1%) of participants reported frequently exposed to social media. After controlling for covariates, frequently SME was positively associated with high odds of anxiety (OR=1.72, 95%CI: 1.31-2.26) and CDA (OR=1.91, 95%CI: 1.52-2.41) compared with less SME.\n",
            "\n",
            "Interpretation: Our findings show there are high prevalence of mental health problems, which positively associated with frequently SME during the COVID-19 outbreak. These findings implicated the government need pay more attention to mental health problems, especially depression and anxiety among general population and combating with “infodemic” while combating during public health emergency.\n",
            "\n",
            "Funding Statement: National key R&D Program of China (grant no. 2018YFC2002000 & 2018YFC2002001) and National Natural Science Foundation of China (grant no. 71573048).\n",
            "\n",
            "Declaration of Interests: The authors declare no competing interests.\n",
            "\n",
            "Ethics Approval Statement: This study has been approved by the Institutional Review Board of Fudan University, School of Public Health (IRB#2020-01-0800).\n",
            "Date: 2020-02-17\n",
            "Full body: None\n",
            "Source: SSRN\n",
            "Source impact factor: None\n",
            "Search keyword: None\n",
            "Category: None\n",
            "Licensing: None\n",
            "Document acquisition date: 2020-03-24\n",
            "Citations: None\n",
            "Organization affiliated: Fudan University - Fudan Institute of Health Communication\n",
            "Keywords: COVID-19, Mental Health, Social Media, Infodemic\n",
            "References: [{'title': '', 'authors': '', 'link': 'https://doi.org/10.1148/radiol.2020200241.podcast'}, {'title': '', 'authors': 'Y Bao, Y Sun, S Meng, J Shi, L Lu', 'link': 'https://doi.org/10.1016/S0140-6736'}, {'title': 'Public responses to the novel 2019 coronavirus (2019-nCoV) in Japan: mental health consequences and target populations', 'authors': 'J Shigemura, R J Ursano, J C Morganstein, M Kurosawa, D M Benedek', 'link': 'https://doi.org/10.1111/pcn.12988'}, {'title': '', 'authors': 'L Kang, Y Li, S Hu', 'link': 'https://doi.org/10.1016/s2215-0366(20)30047-x'}, {'title': '', 'authors': '', 'link': ''}, {'title': 'The 2014 Ebola Outbreak and Mental Health: Current Status and Recommended Response', 'authors': 'J M Shultz, F Baingana, Y Neria', 'link': ''}, {'title': '', 'authors': 'K Bontcheva, G Gorrell, B Wessels', 'link': 'https://doi.org/10.1016/b978-1-84334-749-1.00006-8'}, {'title': '', 'authors': 'Florian Roth, G Brönnimann', 'link': ''}, {'title': '', 'authors': 'Who, Covid', 'link': 'https://doi.org/10.31525/ct1-nct04273321'}, {'title': 'Understanding the mental health effects of indirect exposure to mass trauma through the media', 'authors': 'Y Neria, G M Sullivan', 'link': 'https://doi.org/10.1001/jama.2011.1358'}, {'title': '', 'authors': 'D-H Choi, W Yoo, G-Y Noh, K Park', 'link': ''}, {'title': 'WHO Collaborating Centre in Mental Health. Chinese version of the WHO-Five Well-Being Index', 'authors': 'Y Huang, Y Wang, H Wang', 'link': ''}, {'title': 'A brief measure for assessing generalized anxiety disorder: the GAD-7', 'authors': 'R L Spitzer, K Kroenke, J B Williams, B Lowe', 'link': 'https://doi.org/10.1001/archinte.166.10.1092'}, {'title': 'Assessment of Anxiety and Depression by Self-rating Scales of GAD-7 and PHQ-9 in Cardiovascular Outpatients', 'authors': 'W F Xu, Py, B Q Chen', 'link': ''}, {'title': 'Mental health problems among survivors in hard-hit areas of the 5.12 Wenchuan and 4.20 Lushan earthquakes', 'authors': 'Z Xie, J Xu, Z Wu', 'link': 'https://doi.org/10.1080/09638237.2016.1276525'}, {'title': 'Prevalence of psychological symptoms among Ebola survivors and healthcare workers during the 2014-2015 Ebola outbreak in Sierra Leone: a cross-sectional study', 'authors': 'D Ji, Y J Ji, X Z Duan', 'link': 'https://doi.org/10.18632/oncotarget.14498'}, {'title': 'Long-term psychiatric morbidities among SARS survivors', 'authors': 'I W Mak, C M Chu, P C Pan, M G Yiu, V L Chan', 'link': 'https://doi.org/10.1016/j.genhosppsych.2009.03.001'}, {'title': '', 'authors': 'Xinhua', 'link': ''}, {'title': 'Experimental evidence of massive-scale emotional contagion through social networks', 'authors': 'A D Kramer, J E Guillory, J T Hancock', 'link': 'https://doi.org/10.1073/pnas.1320040111'}, {'title': 'Association of Increased Youth Suicides in the United States With the Release of 13 Reasons Why', 'authors': 'T Niederkrotenthaler, S Stack, B Till', 'link': 'https://doi.org/10.1001/jamapsychiatry.2019.0922'}, {'title': '', 'authors': '', 'link': 'https://doi.org/10.1093/ww/9780199540884.013.41994'}, {'title': '', 'authors': '', 'link': 'https://doi.org/10.1016/s0026-0576(00)81076-4'}]\n",
            "Link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3541120\n",
            "Extra links: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3541120\n",
            "\n",
            "\n",
            "https://hq.ssrn.com/UserHome.cfm?redirectFrom=true\n",
            "Title: Mathematical Recommendations to Fight Against COVID-19\n",
            "Authors: Chenlin GU, Wei Jiang, Tianyuan Zhao, Ban Zheng\n",
            "DOI: SSRN-ID3551006\n",
            "Abstract: The statistics show that the mortality of COVID-19 is 20 times higher than seasonal flu and close to that of Spanish flu, hence it is becoming an absolute priority for every country to take efficient measure to limit the transmission of COVID-19. In this short paper, we propose a mathematical framework to model the contagion of COVID-19 by choosing three key parameters: infection rate, confirmation rate and quarantine efficiency ratio. We use the experience from China to calibrate the parameters, and then study the consequence of different measures. Our research suggest that working in distance and \"distanciation sociale\" (social distancing in French) is an efficient way to limit the contagion as soon as possible and highlight the risk of having a low confirmation rate which happens frequently when hospital is saturated.\n",
            "\n",
            "Funding: None.\n",
            "\n",
            "Declaration of Interest: None.\n",
            "Date: 2020-03-09\n",
            "Full body: None\n",
            "Source: SSRN\n",
            "Source impact factor: None\n",
            "Search keyword: None\n",
            "Category: None\n",
            "Licensing: None\n",
            "Document acquisition date: 2020-03-24\n",
            "Citations: None\n",
            "Organization affiliated: École Normale Supérieure (ENS)\n",
            "Keywords: COVID-19, epidemic modelling process\n",
            "References: [{'title': '', 'authors': 'T Ai, Z Yang, H Hou, C Zhan, C Chen, W Lv, Q Tao, Z Sun, L Xia', 'link': 'https://doi.org/10.1148/radiol.2020200642'}, {'title': '', 'authors': 'Berkeley Lovelace, J Higgins-Dunn, N', 'link': ''}, {'title': 'Centre for the Mathematical Modelling of Infectious Diseases COVID-19 Working Group', 'authors': 'J Hellewell, S Abbott, A Gimma, N I Bosse, C I Jarvis, T W Russell, J D Munday, A J Kucharski, J Edmunds, S Funk, View more', 'link': None}, {'title': '', 'authors': 'N Imai, A Cori, I Dorigatti, M Baguelin, C A Donnelly, S Riley, N M Ferguson', 'link': ''}, {'title': '', 'authors': 'Q Li, X Guan, P Wu, X Wang, L Zhou, Y Tong, R Ren, K S M Leung, E H Y Lau, J Y Wong, View more', 'link': 'https://doi.org/10.1056/nejmoa2001316'}, {'title': '', 'authors': 'N Shao, J Cheng, W Chen', 'link': 'https://doi.org/10.1101/2020.02.17.20023747'}, {'title': '', 'authors': 'K Sheikh, D Watkins, J Wu, M Gröndahl', 'link': ''}, {'title': 'The epidemiological characteristics of an outbreak of 2019 novel coronavirus diseases (COVID-19) in China', 'authors': '', 'link': ''}, {'title': 'Pandemic influenza preparedness and response: a WHO guidance document, World Health Organization', 'authors': '', 'link': ''}, {'title': 'WHO: Coronavirus disease (COVID-19) outbreak', 'authors': '', 'link': ''}, {'title': 'Nowcasting and forecasting the potential domestic and international spread of the 2019-nCoV outbreak originating in Wuhan, China: a modelling study', 'authors': 'J T Wu, K Leung, G M Leung', 'link': 'https://doi.org/10.1016/s0140-6736(20)30260-9'}, {'title': 'Characteristics of and Important Lessons From the Coronavirus Disease 2019 (COVID-19) Outbreak in China: Summary of a Report of 72314 Cases From the Chinese Center for Disease Control and Prevention', 'authors': 'Z Wu, J M Mcgoogan', 'link': ''}]\n",
            "Link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3551006\n",
            "Extra links: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3551006\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}