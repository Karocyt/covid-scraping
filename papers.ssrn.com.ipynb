{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "papers.ssrn.com.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bRcrZmh5i9ew"
      },
      "source": [
        "example https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3539694"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNCXCKWyAlti",
        "outputId": "bb56eedd-070f-4d7d-d952-04468c6abd91",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "!if [ ! -f ArticleScraper.ipynb ]; then curl https://raw.githubusercontent.com/Karocyt/covid-scraping/master/ArticleScraper.ipynb > ArticleScraper.ipynb; else echo \"Already done\"; fi\n",
        "%run ArticleScraper.ipynb"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100 16934  100 16934    0     0    99k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.6/dist-packages (4.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.11.28)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from datetime) (2018.9)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.6/dist-packages (from datetime) (5.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from zope.interface->datetime) (46.0.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (80.0.3987.87-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l_CKHDa_mai_",
        "colab": {}
      },
      "source": [
        "example_dicts = [{'authors': 'C You, Y Deng, W Hu, J Sun, Q Lin, F Zhou… - Available at SSRN …, 2020 - papers.ssrn.com',\n",
        "  'extra_link': 'https://www.medrxiv.org/content/medrxiv/early/2020/02/11/2020.02.08.20021253.full.pdf',\n",
        "  'extra_link_text': '[PDF] medrxiv.org',\n",
        "  'link': 'https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3539694',\n",
        "  'preview': 'Background: The 2019 novel coronavirus (2019-nCoV) outbreak in Wuhan, China has\\nattracted world-wide attention. As of February 11, 2020, a total of 44,730 cases of\\npneumonia associated with the 2019-nCoV were confirmed by the National Health …',\n",
        "  'title': 'Estimation of the Time-Varying Reproduction Number of COVID-19 Outbreak in China'},\n",
        " {'authors': 'J Gao, P Zheng, Y Jia, H Chen, Y Mao… - Available at SSRN …, 2020 - papers.ssrn.com',\n",
        "  'extra_link': '',\n",
        "  'extra_link_text': '',\n",
        "  'link': 'https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3541120',\n",
        "  'preview': 'Background: Huge citizens expos social media during a novel coronavirus disease (COVID-\\n19) outbroke in Wuhan, China. We assess the prevalence of mental health problems and\\nexamine their association with social media exposure. Methods: We conducted a cross …',\n",
        "  'title': 'Mental Health Problems and Social Media Exposure During COVID-19 Outbreak'},\n",
        " {'authors': 'C GU, W Jiang, T Zhao, B Zheng - Available at SSRN 3551006, 2020 - papers.ssrn.com',\n",
        "  'extra_link': '',\n",
        "  'extra_link_text': '',\n",
        "  'link': 'https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3551006',\n",
        "  'preview': 'The statistics show that the mortality of COVID-19 is 20 times higher than seasonal flu and\\nclose to that of Spanish flu, hence it is becoming an absolute priority for every country to take\\nefficient measure to limit the transmission of COVID-19. In this short paper, we propose a …',\n",
        "  'title': 'Mathematical Recommendations to Fight Against COVID-19'},\n",
        "  ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WXSKPyznsTqo",
        "colab": {}
      },
      "source": [
        "class SsrnSingleScraper(ArticleScraper):\n",
        "  page_dict = None\n",
        "\n",
        "  def __init__(self, page_dict):\n",
        "    ArticleScraper.wd.get(page_dict['link'])\n",
        "    self.page_dict = page_dict\n",
        "    ArticleScraper.__init__(self, page_dict['link'])\n",
        "\n",
        "  @property\n",
        "  def title(self):\n",
        "    return self.page.head.title.text.split(' by ')[0]\n",
        "\n",
        "  @property\n",
        "  def authors(self):\n",
        "    return self.page.head.title.text.split(' by ')[1].split(\" ::\")[0]\n",
        "\n",
        "  @property\n",
        "  def doi(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def abstract(self):\n",
        "    div = self.page.find(\"div\", {\"class\": \"abstract-text\"})\n",
        "    text = div.find(\"p\").text\n",
        "    return text\n",
        "\n",
        "  @property\n",
        "  def date(self):\n",
        "    xpath = '//*[@id=\"selectable\"]/text()'\n",
        "    text = self.tree.xpath(xpath)[0]\n",
        "    try:\n",
        "      date = datetime.strptime(text.split(\")\")[-2].split(\"(\")[-1], '%m/%d/%Y')\n",
        "    except:\n",
        "      date = datetime.strptime(text.split(\")\")[-2].split(\"(\")[-1], '%B %d, %Y')\n",
        "    return date.strftime(self.date_format)\n",
        "\n",
        "  @property\n",
        "  def body(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def source(self):\n",
        "    return \"SSRN\"\n",
        "\n",
        "  @property\n",
        "  def source_impact_factor(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def search_keyword(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def categories(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def licence(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def citations(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def organization(self):\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def keywords(self):\n",
        "    keywords = self.page.find(text='Keywords:').parent.parent.text.split(': ')[1]\n",
        "    return \",\".join(keywords.split(';'))\n",
        "\n",
        "  @property\n",
        "  def references(self):\n",
        "    refs_list = self.page.findAll('ol')\n",
        "    links = list(map(lambda a: a.get('href'), refs_list))\n",
        "    print(refs_list)\n",
        "    print(links)\n",
        "    return None\n",
        "\n",
        "  @property\n",
        "  def link(self):\n",
        "    return self.page_dict['link']\n",
        "\n",
        "  @property\n",
        "  def extralinks(self):\n",
        "    return self.page_dict['extra_link']\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dW_w8jyIzwlJ",
        "colab": {}
      },
      "source": [
        "class SsrnScraper():\n",
        "  def parse(self, pages_dict):\n",
        "    for d in pages_dict:\n",
        "      yield SsrnSingleScraper(d).parse()  \n",
        "\n",
        "scraper = SsrnScraper()\n",
        "for d in scraper.parse(example_dicts):\n",
        "  for k in d:\n",
        "    print(k, d[k], sep=\": \")\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}